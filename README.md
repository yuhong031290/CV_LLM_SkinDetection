# Skin Disease AI Assistant

An integrated mobile and backend system for AI-assisted skin disease diagnosis. This project combines a lightweight image classifier and a fine-tuned large language model (LLM), supporting on-device classification and interactive medical Q&A.

## ğŸ©º Motivation

Diagnosing skin diseases is challenging due to diverse symptoms and appearances. This system is designed for:
- Local image classification on mobile devices
- Protecting user privacy (no cloud uploads)
- Fast diagnostic assistance
- Medical Q&A with a fine-tuned LLM

## âœ¨ Features

| Feature            | Description                                             |
|-------------------|---------------------------------------------------------|
| ğŸ“± **Mobile Inference** | On-device skin disease detection using a lightweight TFLite model.     |
| ğŸ§  **LLM Chatbot**       | Fine-tuned LLaMA model for answering medical questions.       |
| ğŸ” **Privacy-Focused**   | Image classification runs entirely offline. No medical images are uploaded.          |
| ğŸš€ **Cross-Platform**   | Built with Flutter for a consistent experience on Android and iOS. |

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|---|---|---|
| **Frontend** | Flutter, Dart | Cross-platform mobile application development. |
| **Backend** | Python | Serves the fine-tuned LLM for Q&A. |
| **CV Model** | MobileNetV2 (TFLite) | Lightweight, on-device image classification. |
| **LLM** | LLaMA3 + LoRA | Advanced, fine-tuned language model for medical dialogue. |

## ğŸ“‚ Project Structure

```
CV_LLM_SkinDetection/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ inference.py          # Backend script to run the LLM.
â”‚   â”œâ”€â”€ llm_fine_tuning.py    # Python script for fine-tuning the LLM.
â”‚   â””â”€â”€ llm_fine_tuning.ipynb # Jupyter Notebook for LLM fine-tuning experiments.
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ main.dart           # Flutter app entry point.
â”‚   â”‚   â”œâ”€â”€ ImageClassifier.dart # Handles TFLite model loading and inference.
â”‚   â”‚   â””â”€â”€ DiseaseInformation.dart # UI components for displaying results.
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â””â”€â”€ *.tflite            # TFLite models for on-device classification.
â”‚   â””â”€â”€ pubspec.yaml          # Flutter project dependencies.
â”‚
â””â”€â”€ Demo.png                    # Screenshot of the application.
```

## ğŸ§  Models

### Image Classifier
- **Framework**: TFLite
- **Architecture**: Based on MobileNetV2 for efficient mobile performance.
- **Deployment**: Runs locally on the user's device via the Flutter app. The model files (`skin.tflite`, `model.tflite`, etc.) are stored in `frontend/assets/`.

### Language Model
- **Architecture**: LLaMA3 fine-tuned with LoRA (Low-Rank Adaptation).
- **Training**: The fine-tuning process is detailed in `backend/llm_fine_tuning.py` and the corresponding notebook.
- **Deployment**: Served by the Python backend (`backend/inference.py`).

## ğŸ–¼ï¸ Demo

<p align="center">
  <img src="Demo.png" alt="Skin Disease AI Assistant Demo" width="800"/>
</p>

## ï¿½ Getting Started

### Prerequisites
- Flutter SDK
- Python 3.8+
- An IDE like VS Code or Android Studio

### 1. Frontend (Flutter App) Setup
```bash
# Navigate to the frontend directory
cd frontend

# Install dependencies
flutter pub get

# Run the app on a connected device or emulator
flutter run
```

### 2. Backend (Python LLM Server) Setup
```bash
# Navigate to the backend directory
cd backend

# It's recommended to create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

# Install Python dependencies (assuming a requirements.txt exists)
# You may need to create one based on the imports in the .py files
pip install -r requirements.txt

# Run the inference server
python inference.py
```

## ï¿½ğŸ“¸ How It Works

Users can either **take a photo** or **upload an image** of their skin condition.
Here's the full inference pipeline:

1. ğŸ“· **User provides a skin image** within the mobile app.
2. ğŸ“± **The app executes the TFLite model locally** for disease classification.
   - All inference runs **on-device**, ensuring privacy and low latency.
3. ï¿½ **The prediction result (text only)** is sent to the backend.
4. ğŸ¤– **The backend's fine-tuned LLaMA model** receives the prediction.
   - It generates a detailed explanation, suggestions, and answers to follow-up questions.
5. ğŸ’¬ **The response is displayed** to the user in the app's chat interface.



